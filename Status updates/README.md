Algorithmic Bias 
1.	What did the algorithm do? 
The algorithm was designed to help hospitals and insurance companies identify which patients will benefit from “high-risk care management” programs, which provide chronically ill people with access to specially trained nursing staff and allocate extra primary-care visits for closer monitoring.
2.	What information did the algorithm use to make its predictions?
It used previous patient health care spending as a proxy for medical needs.
3.	What information did the researchers use to determine that the algorithm was biased?
Race and income are correlated; poorer patients, even when insured, tend to use medical services less frequently or have reduced access to them because of time and location constraints. There is also the preconceived bias with certain groups that they might think they are not going to receive the necessary care they need so they won’t go. 
4.	What was the impact of the algorithmic bias?
The impact of the algorithmic bias led to more white patients being taken care of than black patients due to the information that the algorithm had. 
5.	What were the primary causes of the bias?
There are a couple of reasons the bias existed in the first place. As the paper said race and income are correlated, since white patients spent more money on health care than black patients there was more data on them which led the algorithm to believe that white patients are more needy when it comes to healthcare. This also was created due to the notion that some groups have that they might not get the care they need so they won’t go or that they are okay and only go when they really need it.
6.	How might you address the issues that the researchers found? 
This is a difficult question to answer because of the types of bias that already exist. When it came to the data they used between white and black people, we would need get more data from people that identify as black because the with the data used only 6,079 self-identified as black while 43,539 self-identified as white. This would be the first step we would need to take to be able to make the algorithm less biased. We would also need to include more benchmarks to be able to give a clearer picture of patient health. 

